# %% Imports
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import RidgeClassifier, LogisticRegression
from sklearn.svm import SVC
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier
from sklearn.metrics import (
    accuracy_score,
    classification_report,
    roc_auc_score,
    f1_score,
    confusion_matrix,
)
from sklearn.feature_extraction.text import TfidfVectorizer
import random
import re


# %% Seed
def set_seed(seed=42):
    random.seed(seed)
    np.random.seed(seed)


set_seed(42)

# %% ë°ì´í„° ë¡œë“œ
df = pd.read_csv("KoreanData.csv")
df = df[df["input_text_long"].notnull()]
df = df[df["answer_rate"].notnull()]
df["answer_rate"] = df["answer_rate"].astype(float)


# %% í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
def preprocess(text):
    text = re.sub(r"[^\w\s]", "", text)
    return text


texts = [preprocess(t) for t in df["input_text_long"].tolist()]

# %% TF-IDF ë²¡í„°í™”
print("ğŸ” TF-IDF ë²¡í„°í™” ì¤‘...")
tfidf_vectorizer = TfidfVectorizer(max_features=5000)
embeddings = tfidf_vectorizer.fit_transform(texts).toarray()
print(f"âœ… ì„ë² ë”© shape: {embeddings.shape}")


# %% ë“±ê¸‰ ë¼ë²¨ ìƒì„±
def answer_rate_to_class(rate):
    if rate >= 90:
        return 5  # í•˜
    elif rate >= 80:
        return 4  # ì¤‘í•˜
    elif rate >= 60:
        return 3  # ì¤‘
    elif rate >= 50:
        return 2  # ì¤‘ìƒ
    else:
        return 1  # ìƒ


df["label"] = df["answer_rate"].apply(answer_rate_to_class)

# %% ë°ì´í„° ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(
    embeddings, df["label"].values, test_size=0.2, random_state=42, stratify=df["label"]
)
print(X_train.shape, y_train.shape)

# %% ëª¨ë¸ ë¦¬ìŠ¤íŠ¸


models = {
    "LightGBM": LGBMClassifier(
        n_estimators=500, learning_rate=0.05, max_depth=7, random_state=42, verbose=-1
    ),
    "RandomForest": RandomForestClassifier(
        n_estimators=500, max_depth=10, random_state=42, n_jobs=-1
    ),
    "LogisticRegression": LogisticRegression(max_iter=1000, multi_class="ovr"),
    "SVC": SVC(C=1.0, probability=True),
    "CatBoost": CatBoostClassifier(
        iterations=500, learning_rate=0.05, depth=7, verbose=0, random_state=42
    ),
}


# %% í‰ê°€ í•¨ìˆ˜
def evaluate_classifier(name, model):
    model.fit(X_train, y_train)
    train_preds = model.predict(X_train)
    test_preds = model.predict(X_test)
    test_probs = model.predict_proba(X_test)

    acc = accuracy_score(y_test, test_preds)
    f1_macro = f1_score(y_test, test_preds, average="macro")
    f1_weighted = f1_score(y_test, test_preds, average="weighted")
    try:
        auroc_macro = roc_auc_score(
            y_test, test_probs, multi_class="ovr", average="macro"
        )
        auroc_weighted = roc_auc_score(
            y_test, test_probs, multi_class="ovr", average="weighted"
        )
    except ValueError:
        auroc_macro, auroc_weighted = None, None

    print(f"\nğŸš€ {name} ë¶„ë¥˜ ê²°ê³¼")
    print(f"Accuracy: {acc:.4f}")
    print(f"F1-score (macro): {f1_macro:.4f} | (weighted): {f1_weighted:.4f}")
    if auroc_macro:
        print(f"AUROC (macro): {auroc_macro:.4f} | (weighted): {auroc_weighted:.4f}")
    else:
        print(f"âš ï¸ AUROC ê³„ì‚° ë¶ˆê°€ (í´ë˜ìŠ¤ ê²°ì¸¡)")

    print("\nğŸ“Š Classification Report:")
    print(classification_report(y_test, test_preds, digits=4))
    print("ğŸ“Œ Confusion Matrix:")
    print(confusion_matrix(y_test, test_preds))


# %% ëª¨ë¸ë³„ í‰ê°€
for name, model in models.items():
    evaluate_classifier(name, model)

# %%
